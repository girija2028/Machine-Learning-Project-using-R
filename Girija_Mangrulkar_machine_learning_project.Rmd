---
title: "Machine Learning Project"
---


**Your Name**:Girija Mangrulkar
**Your G Number**: G01284807



```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

library(tidyverse)

library(tidymodels)
library(discrim)

credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))

```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**:
Is there any relation between the credit limit and customer income with respect to customer account status?

**Answer**:
Yes, there is definitely a relation which we can infer from the following graph: We can observe that credit limit is directly proportional to customer's income which is obvious and is base of the credit card company. Along with that we can also observe that 'more the income' - more is the active accounts. The green points on the higher side is seen on the one with Bachelors Degree as they tend to earn more and hence they have less number of closed accounts. 

```{r}
credit_card_df %>%
  group_by(education) %>%
  summarise(No_of_Customers = n(),
            active_customers = sum(customer_status == 'active'), 
            closed_customers = sum(customer_status == 'closed_account'),
            percent_closed = round(100 * mean(customer_status == 'closed_account'),1))

ggplot(data = credit_card_df, aes(x = credit_limit, y = income, color = customer_status))+
  geom_point()+
  scale_color_manual(values = c('red', 'blue'))+
  facet_wrap(education~., nrow = 1)+
  labs(title = " Credit Limit vs Income by Customer Status",
       x = "Credit Limit",
       y = "Customer Income ")
```



# Question 2


**Question**:
How does the total spends last year influence the customer status?

**Answer**:
We can observe from the below graphs and the data that customers whose average expenditure is more in the past year tend to close their accounts lesser than the ones who spend less. The average total last year spends for the closed accounts is $ 3120 and for the active accounts is $4596. 

```{r}
credit_card_df %>%
  group_by(customer_status) %>%
  summarise(No_of_Customers = n(),
            minimum_spends = min(total_spend_last_year),
            max_spends = max(total_spend_last_year),
            average_spends = mean(total_spend_last_year))

ggplot(credit_card_df, aes(x = customer_status, y = total_spend_last_year, fill = customer_status)) + 
  geom_boxplot()+
  scale_fill_manual(values = c('red', 'blue'))+
  labs(title = "Box Plots of Customer Status to Total Spends",
       x = "Customer Status",
       y = "Total Spends Last Year")+
  theme_light()
```


# Question 3


**Question**:
What is the impact of employment status on the customer status or how are they co-related?

**Answer**:
In the below graph, we can see that the people with the part time Employment Status are the ones who closed their credit card account the highest out of 3 employment statuses. We can also observe that customers who are self-employed are the ones with the highest active_customers in the employment status. 


```{r}
credit_card_df %>%
  group_by(employment_status) %>%
  summarise(n_customers = n(),
            active_customer = sum(customer_status == 'active'),
            closed_customer = sum(customer_status == 'closed_account'),
            active_percent = round(100 * mean(customer_status == 'active'),1),
            closed_percent = round(100 * mean(customer_status == 'closed_account'),1))

ggplot(data = credit_card_df, mapping = aes(x = employment_status, fill = customer_status)) +
  geom_bar(color = 'black',stat = "count", position = "fill") + 
  scale_fill_manual(values = c('red', 'blue'))+
  labs(title = "Employment Status to Customer Status",
       x = "Employment Status",
       y = " Proportion of Customers")+
  coord_flip()+
  theme_light()
```



# Question 4


**Question**:
Which card type have been closed the most? Also, find the correlation between the marital status and the most unsuccessful card type.

**Answer**:
We can see that 'Blue' type of card is bought by most of the customers and also the one which has been closed by about 58.7% of the card holders. This shows that there is something wrong with the policies or perks offered in this type of card. 

When compared the 'Blue' type of card with the type of marital status - it was observed that the 'Married' as marital status was the one which issued most of the 'Blue' type of credit card. So, the perks for the 'Married' in Blue of type of category is the least and there should be some investigation to be carried in this category on why couples tend to close their account. 

```{r}
credit_card_df %>%
              group_by(card_type) %>%
              summarise(no_of_customers = n(),
              customer_closed = sum(customer_status == 'closed_account'),
              customer_active = sum(customer_status == 'active'),
              percentage_closed = round(100*(customer_closed/no_of_customers),1))

credit_card_df %>%
              group_by(card_type == 'blue') %>%
              summarise(no_of_customers = n(),
              Single = sum(marital_status == 'single'),
              Married = sum(marital_status == 'married'),
              Divorced = sum(marital_status == 'divorced'),
              percentage_single = round(100*(Single/no_of_customers),1),
              percentage_married = round(100*(Married/no_of_customers),1),
              percentage_divorced = round(100*(Divorced/no_of_customers),1))  

ggplot(credit_card_df, aes(x = marital_status, y = card_type)) + geom_count(aes(color = ..n..))
```



# Question 5


**Question**:
Is there any comparison between the Educational level and the Customer Status?

**Answer**:
We see that there are 3 Educational Level in the given data set and we observe that 'Bachelors' have the highest active percentage of the accounts in the bank i.e., 57.1% whereas on the other side we see that 'Doctorate' educational level class is the one who are closing the maximum accounts which is 53.4% which is more than half.

```{r}
credit_card_df %>%
              group_by(education) %>%
              summarise(no_of_customers = n(),
              customer_closed = sum(customer_status == 'closed_account'),
              customer_active = sum(customer_status == 'active'),
              percentage_closed = round(100*(customer_closed/no_of_customers),1),
              percentage_active = round(100*(customer_active/no_of_customers),1))

ggplot(data = credit_card_df, mapping = aes(x = education, fill = customer_status)) +
  geom_bar(color = 'black', stat = "count", position = "fill", width = 0.5) + 
  scale_fill_manual(values = c('red', 'blue'))+
  labs(title = "Educational Level to Customer Status",
       x = "Educational Level",
       y = "Number of Customers")+
  theme_light()
```




# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data




# Model 1- Logistic regression

#Data splitting

```{r}
credit_card_df<-credit_card_df %>%
  mutate(customer_status = factor(customer_status, levels = c('active','closed_account')))
set.seed(271)

credit_card_split <- initial_split(credit_card_df, prop = 0.75,
                              strata = customer_status)

credit_card_training <- credit_card_split %>% training()

credit_card_test <- credit_card_split %>%
               testing()


# Create cross validation folds for hyperparameter tuning
set.seed(271)

credit_card_folds <- vfold_cv(credit_card_df, v = 5)
```

#Feature engineering

```{r}
credit_recipe <- recipe(customer_status ~ ., data = credit_card_training) %>% 
                 step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                 step_normalize(all_numeric(), -all_outcomes()) %>% 
                 step_dummy(all_nominal(), -all_outcomes())
```

#Check Transformation

```{r}
credit_recipe %>% 
  prep(training = credit_card_training) %>% 
  bake(new_data = NULL)

```

#Specify Logistic regression model

```{r}
logistic_model1 <- logistic_reg() %>% 
                  set_engine('glm') %>% 
                  set_mode('classification')
```

#Create a workflow

```{r}
logistic_workflow <- workflow() %>% 
               add_model(logistic_model1) %>% 
               add_recipe(credit_recipe)
```

#Fit model

```{r}
logistic_fit <- logistic_workflow %>% 
                last_fit(split = credit_card_split)
```

#Collect prediction

```{r}
logistic_results <-  logistic_fit %>%
  collect_predictions()
```

#Evaluate model performances

```{r}
## ROC Curve
roc_curve(logistic_results, 
          truth = customer_status, 
          estimate = .pred_active) %>% 
  autoplot()

# ROC AUC
roc_auc(logistic_results, 
        truth = customer_status,
        .pred_active)

# Confusion Matrix
conf_mat(logistic_results, 
         truth = customer_status, 
         estimate = .pred_class)
```
```{r}
logistic_fit %>% collect_metrics()
```


# Model 2- Decision tree

```{r}
tree_model <- decision_tree(cost_complexity = tune(),
                            tree_depth = tune(),
                            min_n = tune()) %>% 
              set_engine('rpart') %>% 
              set_mode('classification')
```

#workflow

```{r}
tree_workflow <- workflow() %>% 
                 add_model(tree_model) %>% 
                 add_recipe(credit_recipe)

```


```{r}
## Create a grid of hyperparameter values to test
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)
```

```{r}
# View grid
tree_grid
```
```{r}
tree_grid <- grid_regular(parameters(tree_model), 
                          levels = 2)
```


```{r}
tree_grid
```

```{r}
## Tune decision tree workflow
set.seed(271)

tree_tuning <- tree_workflow %>% 
               tune_grid(resamples = credit_card_folds,
                         grid = tree_grid)
```

```{r}
## Show the top 5 best models based on roc_auc metric
tree_tuning %>% show_best('roc_auc')
```

```{r}
## Select best model based on roc_auc
best_tree <- tree_tuning %>% 
             select_best(metric = 'roc_auc')

# View the best tree parameters
best_tree
```
```{r}
final_tree_workflow <- tree_workflow %>% 
                       finalize_workflow(best_tree)
```

```{r}
tree_wf_fit <- final_tree_workflow %>% 
               fit(data = credit_card_training)
```

```{r}
tree_fit <- tree_wf_fit %>% 
            pull_workflow_fit()
```

```{r}
library(vip)
vip(tree_fit)
```

```{r fig.height = 40, fig.width = 25}
library(rpart.plot)
rpart.plot(tree_fit$fit, roundint = FALSE)
```

```{r}
tree_last_fit <- final_tree_workflow %>% 
                 last_fit(credit_card_split)
```

```{r}
tree_last_fit %>% collect_metrics()
```

```{r}
tree_last_fit %>% collect_predictions() %>% 
                  roc_curve(truth  = customer_status, estimate = .pred_active) %>% 
                  autoplot()
```

```{r}
tree_predictions <- tree_last_fit %>% collect_predictions()

conf_mat(tree_predictions, truth = customer_status, estimate = .pred_class)

```


# Model 3-Random Forest

```{r}
credit_cf_model <- rand_forest(mtry = tune(),
                        trees = tune(),
                        min_n = tune()) %>% 
                        set_engine('ranger', importance = "impurity") %>% 
                        set_mode('classification')
```


```{r}
credit_cf_workflow <- workflow() %>% 
                      add_model(credit_cf_model) %>% 
                      add_recipe(credit_recipe)
```

```{r}
credit_cf_grid <- grid_random(mtry() %>% range_set(c(5, 15)),
                                       trees(),
                                       min_n(),
                                       size = 10)
```

```{r}
credit_cf_grid
```

```{r}
set.seed(271)
credit_cf_tuning <- credit_cf_workflow %>% 
                    tune_grid(resamples = credit_card_folds,
                    grid = credit_cf_grid)
```

```{r}
best_cf <- credit_cf_tuning %>% 
           select_best(metric = 'roc_auc')

best_cf
```

```{r}
final_credit_cf_workflow <- credit_cf_workflow %>% 
                            finalize_workflow(best_cf)
```

```{r}
credit_rf_wf_fit <- final_credit_cf_workflow %>% 
                  fit(data = credit_card_training)
```

```{r}
credit_rf_fit <-  credit_rf_wf_fit %>% 
                  extract_fit_parsnip()
```

```{r}
credit_rf_last_fit <- final_credit_cf_workflow %>% 
                      last_fit(credit_card_split)
```

```{r}
lastfit_rf_results <- credit_rf_last_fit %>% 
                      collect_predictions()

lastfit_rf_results
```

```{r}
vip(credit_rf_fit)
```

```{r}
lastfit_rf_results %>% 
                roc_curve(truth = customer_status, estimate = .pred_closed_account) %>% 
                autoplot() 
```

```{r}
credit_rf_last_fit %>% collect_metrics()
```

```{r}
lastfit_rf_results %>% conf_mat(truth = customer_status, estimate = .pred_class)
```

```{r}
lastfit_rf_results %>% f_meas(truth = customer_status, estimate = .pred_class)
```

# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?

<br>

2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section

<br>

3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a bank with limited knowledge of machine learning.

<br>

4. Your recommendations to the bank on how to reduce the number of customers closing their credit card accounts 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**

Add your summary here. Please do not place your text within R code chunks.

A dataset of a struggling U.S. Bank was explored, visualized, and analyzed. The objective of this project is to explore the factors that lead to customers canceling their credit card accounts. The bank is trying to understand the contributing factors towards the same. This analysis is important because the bank has been suffering great losses over the past years and finding a root cause will help the bank to make changes in their company policies and their strategies for the future. 

After the analysis was carried out following were the key findings in the existing dataset - 

We saw that there are 3 Educational Level in the given data set and observed that 'Bachelors' have the highest active percentage of the accounts in the bank i.e., 57.1% whereas on the other side we see that 'Doctorate' educational level class is the one who is closing the maximum accounts which are 53.4% which is more than half. Banks should retrospect this particular educational level on why this class is closing their account on a majority basis. 
Moreover, a card type was visually analyzed and we observed that the 'Blue' type of card is bought by most of the customers and also the one which has been closed by about 58.7% of the cardholders. This shows that there is something wrong with the policies or perks offered in this type of card. 
When compared the 'Blue' type of card with the type of marital status - it was observed that the 'Married' as marital status was the one which issued most of the 'Blue' type of credit card. So, the perks for the 'Married' in Blue of type of category is the least and there should be some investigation to be carried in this category on why couples tend to close their account. 
When employment status was observed over how it impacted the customer status, we saw that the people with the part-time Employment Status are the ones who closed their credit card account the highest out of 3 employment statuses. We can also observe that self-employed customer are the ones with the highest active_customers in the employment status. Bank should take this factor into consideration over what makes part-time employees tend to close their accounts in a short period. 
Additionally, we can observe from the below graphs and the data that customers whose average expenditure is more in the past year tend to close their accounts lesser than the ones who spend less. The average total last year spends for the closed accounts is $3120 and for the active accounts is $4596. 

The bank should look into these suggestions and analyses and take immediate and suitable steps for generating greater revenue and profitability. 

There were three classification models which were applied to the given dataset namely: 


1.	Logistic Regression 
2.	Decision tree
3.	Random Forest 

The accuracy of the mentioned models is as follows 

Model 	              Accuracy %	
Logistic Regression 	86.25%	      
Decision tree	        91.18%	      
Random forest         94.90%	    

After the modeling process was carried out we observed that Random Forest Classification Model gave an accuracy of up to 94.90% out of all three models. This is a very good model with roc_auc accuracy and F-score of up to 98.92 and 95.29% respectively. 

Plotting the Importance with respect to the predictor variable. We observe that transactions_last_year, total_spend_last_year, and utilization_ratio play a significant role in predicting the output variable. Banks have to examine these factors closely and then come to a conclusion on how these factors affected the customers closing their accounts. 

F-score is an overall measure of a model’s accuracy that combines precision and recall. A good F1 score means that we have low false positives and low false negatives. 

In the case of Random Forest :

False Positive: 37
False Negative: 22

Which is very low and that is one of the factors which helps us in selecting the model. A good model means it will help us in predicting the output which is Customer Closing the account in the future or not. This will help the Bank to analyze every customer’s preferences and offer them the most viable solution so that they don’t close the account in the future and the bank’s profits have an upward curve. 

Suggestions: 

-	The bank should have transparent policies over the charges which will be incurred later on and not now. The customers tend to close their accounts due to some hidden charges applied to them afterward.

-	Make changes in the ‘Blue’ card type which is the worst-performing and add more types of cashback, perks, offers, etc.

-	Employment status affects the mood of many customers – from the past data we concluded that part-time employees are the worst-performing customers and we should consult them.

-	Give close attention to the educational level as ‘Doctorate’ and find out their requirements and make changes to the policies.

All in all, the company’s prime goal should be reducing the risks involved, increase the profitability and the revenue metrics. This could be achieved when there are more customers retained. Retention will only happen when you know what the customer wants and live upto their expectations. 

